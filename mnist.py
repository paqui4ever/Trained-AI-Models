# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19CN2_yrA6obqQ6ZYTHGjR2W5GdEml_dG
"""

import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset
import torch.nn as nn
import torchvision
import matplotlib.pyplot as plt
import torch.optim as optim
from tqdm import tqdm

device = torch.device("cuda") # Defino mi device para poder usar la GPU

ds = torchvision.datasets.MNIST(root = "./data", download = True, train = True) # Defino mi dataset, que lo bajo de los ds de torchvision

ds[0] # Aplicando np.array() sobre cada primer elemento de las tuplas de ds paso la PIL image a array de numpys

x_total = torch.tensor(list(map(lambda z: np.array(z[0]), ds)), dtype=torch.float32).to(device) # Convierto en tensor de tensores a la
                                                                                                # lista de primeros elementos de las tuplas de ds
y_total = (torch.nn.functional.one_hot(torch.tensor(list(map(lambda z: z[1], ds))), num_classes=10)).to(torch.float32).to(device) # Paso todos los labels convertidos en tensores a one hot encoding
                                                                                                                                  #para ver que número del 0 al 9 está siendo representado

x_total.shape, y_total.shape

"""Divido el dataset original en training y testing, creo sus loaders"""

x_train = x_total[:50000].view(-1,1,28,28)
y_train = y_total[:50000]
x_test = x_total[50000:].view(-1,1,28,28)
y_test = y_total[50000:]

train_dataset = TensorDataset(x_train, y_train)
train_loader = torch.utils.data.DataLoader (dataset = train_dataset, batch_size = 32, shuffle = True)
test_dataset = TensorDataset(x_test, y_test)
test_loader = torch.utils.data.DataLoader (dataset = test_dataset, batch_size = 32, shuffle = True)

"""Creo el modelo


---


"""

x_train.shape

model = nn.Sequential(
    # Primera convolutional layer
    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),
    nn.ReLU(),
    # Segunda convolutional layer
    nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=3, stride=2, padding=1),
    nn.ReLU(),
    # Aplano las dos convolutional layers
    nn.Flatten(),
    nn.Linear(64 * 14 * 14, 128),
    nn.ReLU(),
    nn.Linear(128,10)
).to(device)

data_iter = iter(train_loader) # Hago iterable el loader del training set
img_batch = next(data_iter) # Divido en batches aprovechando que es iterable con next()

img_batch[0].shape # Verifico tamaño de los batches

"""Entreno el modelo con un loop de entrenamiento

"""

criterion = nn.MSELoss().to(device)
optimizer = optim.SGD(model.parameters(), lr=1e-3)
test_iter = iter(test_loader)
test_batch = next(test_iter)
num_epochs = 100
for epoch in range(num_epochs):
  for inputs, targets in tqdm(train_loader):
      inputs = inputs.to(device).float()  # Muevo entradas a la GPU y convertir a float
      targets = targets.to(device).float()
      optimizer.zero_grad()  # Reinicio gradientes acumulados
      outputs = model(inputs)  # Calculo predicciones
      loss = criterion(outputs.squeeze(), targets.float())  # Calculo la pérdida
      loss.backward()  # Retropropagación
      optimizer.step()

  correct_predictions = 0
  total_predictions = 0

  with torch.no_grad(): # Por cada epoch pruebo el accuracy del modelo con el dataset de testing
    for test_inputs, test_targets in test_loader:
      test_inputs = test_inputs.to(device).float()
      test_targets = test_targets.to(device).long()
      test_outputs = model(test_inputs)
      _, predicted = torch.max(test_outputs, 1)
      correct_predictions += (predicted == torch.argmax(test_targets, dim=1)).sum().item()
      total_predictions += test_targets.size(0)

  accuracy = (correct_predictions / total_predictions) * 100
  print(f"Accuracy: {accuracy}")

"""Pruebo el modelo con una parte del test dataset

"""

image, label = test_dataset[1]
image = image.unsqueeze(0).to(device) # Le agrego una dimension en la posición 0 así pasa bien por el conv2d del modelo
# Hago la predicción desactivando el descenso de gradiente para que sea mas rapido
with torch.no_grad():
    output = model(torch.tensor(image)).to(device)

# Obtengo la clase predicha (índice de la salida con mayor valor de probabilidad, o sea el indice de qué clase tiene más probabilidad de ser la correcta)
predicted_class = output.argmax(dim=1).item()

print(f'Predicted class: {predicted_class}')
image = image.squeeze(0).cpu().numpy()  # Elimina una dimensión al batch (la agregada al principio) y mueve la imagen a la CPU

plt.imshow(image[0], cmap='gray')
plt.show()